import streamlit as st
from PIL import Image
from langchain_community.chat_models import ChatOllama
from langchain_core.messages import HumanMessage, AIMessage
from src.routing_retriever import ActRoutingRetriever
from src.config import MODEL_NAME, SERVER_URL, RETRIEVER_K
from src.embeddings import build_embeddings
from src.vectorstore import build_vector_store
from src.prompts import QA_PROMPT, DOCUMENT_PROMPT
from src.rag_chain import build_rag_chain

# ---------- Ustawienia strony ----------
st.set_page_config(
    page_title="Asystent Prawny AI", 
    page_icon="锔", 
    layout="wide"
)

# ---------- Zaawansowany CSS (Efekty Hover i Layout) ----------
st.markdown(
    """
    <style>
    /* Kontener wejciowy chat_input */
    [data-testid="stChatInput"] {
        max-width: 850px;
        margin-left: auto;
        margin-right: auto;
        margin-bottom: 40px;
        border-radius: 20px;
        border: 1px solid #e0e0e0;
    }

    /* --- ANIMACJA IKONEK I KURSOR --- */
    /* Celujemy w przycisk wysyania i ikon dodawania plik贸w */
    [data-testid="stChatInput"] button, 
    [data-testid="stChatInput"] label[data-testid="stWidgetLabel"] {
        transition: transform 0.2s ease-in-out !important;
        cursor: pointer !important; /* <--- TUTAJ DODANO EFEKT POINTERA */
    }

    /* Powikszenie przycisku wylij po najechaniu */
    [data-testid="stChatInput"] button:hover {
        transform: scale(1.18) !important;
    }

    /* Powikszenie ikony plusa (upload) po najechaniu */
    [data-testid="stChatInput"] label:hover {
        transform: scale(1.18) !important;
    }

    /* Styl dla 藕r贸de prawnych */
    .source-box {
        background-color: #f8f9fa;
        padding: 15px;
        border-radius: 10px;
        margin-bottom: 10px;
        border-left: 4px solid #ff4b4b;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }

    /* Marginesy g贸wnego kontenera */
    .block-container {
        padding-top: 2rem;
        max-width: 900px;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ---------- Stan sesji ----------
if "messages" not in st.session_state:
    st.session_state.messages = []

if "rag_ready" not in st.session_state:
    st.session_state.rag_ready = False

# ---------- Inicjalizacja RAG (Bez zmian w logice) ----------
@st.cache_resource(show_spinner=True)
def init_rag():
    llm = ChatOllama(
        base_url=SERVER_URL,
        model=MODEL_NAME,
        temperature=0.2,
    )
    embeddings = build_embeddings()
    db, _ = build_vector_store(embeddings)

    retriever = ActRoutingRetriever(
        vectorstore=db,
        k=RETRIEVER_K,
        max_acts=2,
        debug=True,
        search_type="mmr",
        fetch_k=60,
        lambda_mult=0.6,
        enable_sanction_filter=True,
        sanction_k=6,
    )

    rag_chain = build_rag_chain(llm, retriever, QA_PROMPT, DOCUMENT_PROMPT)
    return rag_chain, retriever

if not st.session_state.rag_ready:
    with st.spinner(" Inicjalizacja bazy przepis贸w..."):
        rag_chain, retriever = init_rag()
        st.session_state.rag_chain = rag_chain
        st.session_state.retriever = retriever
        st.session_state.rag_ready = True

# ---------- Ekran G贸wny ----------

st.title("锔 Asystent Prawny AI")
st.markdown("Skonsultuj problem prawny w oparciu o aktualne kodeksy.")

# ---------- Wywietlanie Historii ----------
if not st.session_state.messages:
    st.write("")
    st.info("Zadaj pytanie, aby rozpocz analiz. Mo偶esz przecign dokumenty bezporednio do pola tekstowego.")

for msg in st.session_state.messages:
    avatar = "" if msg["role"] == "user" else "锔"
    with st.chat_message(msg["role"], avatar=avatar):
        st.markdown(msg["content"])

# ---------- Logika RAG ----------
def run_rag_pipeline(user_query: str):
    rag_chain = st.session_state.rag_chain
    result = rag_chain.invoke({"input": user_query}) 
    return result.get("answer", ""), result.get("context", [])

# ---------- INPUT ----------
chat_value = st.chat_input(
    "Napisz pytanie lub zacz pliki...",
    accept_file="multiple",
    file_type=["pdf", "png", "jpg"]
)

if chat_value:
    user_text = chat_value.text or ""
    user_files = chat_value.files or []

    if user_text.strip() or user_files:
        # 1. User Message
        st.session_state.messages.append({"role": "user", "content": user_text})
        with st.chat_message("user", avatar=""):
            st.markdown(user_text)

        # 2. AI Response
        with st.chat_message("assistant", avatar="锔"):
            message_placeholder = st.empty()
            with st.spinner("锔 Analizuj tre akt贸w prawnych..."):
                answer_text, final_docs = run_rag_pipeline(user_text)
                message_placeholder.markdown(answer_text)
                
                if final_docs:
                    with st.expander(" Wykorzystane 藕r贸da"):
                        for doc in final_docs:
                            src = doc.metadata.get("source", "Dokument").split("/")[-1]
                            act = doc.metadata.get("act_name", "Przepis")
                            st.markdown(
                                f"""
                                <div class="source-box">
                                    <strong>{act}</strong> <small>({src})</small><br>
                                    <p style="font-size: 0.85rem; color: #444; margin-top: 8px;">
                                    "{doc.page_content[:350]}..."
                                    </p>
                                </div>
                                """, 
                                unsafe_allow_html=True
                            )

        # 3. Save History
        st.session_state.messages.append({"role": "assistant", "content": answer_text})